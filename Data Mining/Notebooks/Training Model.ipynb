{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Package\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width    variety  label\n",
       "0             5.1          3.5           1.4          0.2     Setosa      0\n",
       "1             4.9          3.0           1.4          0.2     Setosa      0\n",
       "2             4.7          3.2           1.3          0.2     Setosa      0\n",
       "3             4.6          3.1           1.5          0.2     Setosa      0\n",
       "4             5.0          3.6           1.4          0.2     Setosa      0\n",
       "..            ...          ...           ...          ...        ...    ...\n",
       "145           6.7          3.0           5.2          2.3  Virginica      2\n",
       "146           6.3          2.5           5.0          1.9  Virginica      2\n",
       "147           6.5          3.0           5.2          2.0  Virginica      2\n",
       "148           6.2          3.4           5.4          2.3  Virginica      2\n",
       "149           5.9          3.0           5.1          1.8  Virginica      2\n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal.length    float64\n",
       "sepal.width     float64\n",
       "petal.length    float64\n",
       "petal.width     float64\n",
       "variety          object\n",
       "label             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cek tipedata df\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal.length', 'sepal.width', 'petal.length', 'petal.width', 'variety',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Akses kolom df\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,\n",
       "       4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,\n",
       "       5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,\n",
       "       5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. , 7. , 6.4,\n",
       "       6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5. , 5.9, 6. , 6.1, 5.6,\n",
       "       6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7,\n",
       "       6. , 5.7, 5.5, 5.5, 5.8, 6. , 5.4, 6. , 6.7, 6.3, 5.6, 5.5, 5.5,\n",
       "       6.1, 5.8, 5. , 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3,\n",
       "       6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5,\n",
       "       7.7, 7.7, 6. , 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2,\n",
       "       7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6. , 6.9, 6.7, 6.9, 5.8,\n",
       "       6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Akses kolom sepal.length\n",
    "df['sepal.length'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Akses hanya nilai semua kolom\n",
    "feature = df[['sepal.length', 'sepal.width', 'petal.length', 'petal.width']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Akses label\n",
    "label = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubah ke numpy array\n",
    "x = np.array(feature)\n",
    "y = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{x-mean}{std}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mencari rata-rata per kolom / per atribut\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "atribut_mean = x.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "atribut_std = x.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.16971425e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.74885626e+00, -3.62176246e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.37177559e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.87002413e+00, -1.31979479e-01, -1.51073881e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.25060772e-02,  2.16998818e+00, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.73673948e-01,  3.09077525e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.39706395e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.73673948e-01,  1.70959465e+00, -1.16971425e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.28338910e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.16971425e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  1.24920112e+00, -1.56757623e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  5.58610819e-01, -1.16971425e+00,\n",
       "        -9.20547742e-01],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.05603939e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00, -1.31979479e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  1.01900435e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-7.79513300e-01,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  9.82172869e-02, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  2.40018495e+00, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-4.16009689e-01,  2.63038172e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  3.28414053e-01, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-4.16009689e-01,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.74885626e+00, -1.31979479e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.62768839e+00, -1.74335684e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.74885626e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.22655167e+00,\n",
       "        -7.88915558e-01],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.05603939e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  3.28414053e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-6.58345429e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  5.58610819e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [ 1.40150837e+00,  3.28414053e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [-4.16009689e-01, -1.74335684e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 7.95669016e-01, -5.92373012e-01,  4.78571135e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  4.21733708e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  5.35408562e-01,\n",
       "         5.27406285e-01],\n",
       "       [-1.14301691e+00, -1.51316008e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 9.16836886e-01, -3.62176246e-01,  4.78571135e-01,\n",
       "         1.32509732e-01],\n",
       "       [-7.79513300e-01, -8.22569778e-01,  8.07091462e-02,\n",
       "         2.64141916e-01],\n",
       "       [-1.02184904e+00, -2.43394714e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  2.51221427e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  1.37546573e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 3.10997534e-01, -3.62176246e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -3.62176246e-01, -8.98031345e-02,\n",
       "         1.32509732e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  1.94384000e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 4.32165405e-01, -1.97355361e+00,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-2.94841818e-01, -1.28296331e+00,  8.07091462e-02,\n",
       "        -1.30754636e-01],\n",
       "       [ 6.86617933e-02,  3.28414053e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  5.35408562e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 6.74501145e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 9.16836886e-01, -1.31979479e-01,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.15917263e+00, -5.92373012e-01,  5.92245988e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  7.05920842e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.89829664e-01, -3.62176246e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -1.05276654e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00,  2.38717193e-02,\n",
       "        -1.30754636e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00, -3.29657076e-02,\n",
       "        -2.62386821e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  8.07091462e-02,\n",
       "         8.77547895e-04],\n",
       "       [ 1.89829664e-01, -8.22569778e-01,  7.62758269e-01,\n",
       "         5.27406285e-01],\n",
       "       [-5.37177559e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01,  7.88807586e-01,  4.21733708e-01,\n",
       "         5.27406285e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  5.35408562e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 5.53333275e-01, -1.74335684e+00,  3.64896281e-01,\n",
       "         1.32509732e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.28296331e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.05276654e+00,  3.64896281e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  4.78571135e-01,\n",
       "         2.64141916e-01],\n",
       "       [-5.25060772e-02, -1.05276654e+00,  1.37546573e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.02184904e+00, -1.74335684e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-2.94841818e-01, -8.22569778e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [-1.73673948e-01, -1.31979479e-01,  2.51221427e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.73673948e-01, -3.62176246e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 4.32165405e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [-9.00681170e-01, -1.28296331e+00, -4.30827696e-01,\n",
       "        -1.30754636e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  1.27429511e+00,\n",
       "         1.71209594e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.52267624e+00, -1.31979479e-01,  1.21745768e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 5.53333275e-01, -3.62176246e-01,  1.04694540e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  1.16062026e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.12851559e+00, -1.31979479e-01,  1.61531967e+00,\n",
       "         1.18556721e+00],\n",
       "       [-1.14301691e+00, -1.28296331e+00,  4.21733708e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.76501198e+00, -3.62176246e-01,  1.44480739e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00, -1.28296331e+00,  1.16062026e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.64384411e+00,  1.24920112e+00,  1.33113254e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 7.95669016e-01,  3.28414053e-01,  7.62758269e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -8.22569778e-01,  8.76433123e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00, -1.31979479e-01,  9.90107977e-01,\n",
       "         1.18556721e+00],\n",
       "       [-1.73673948e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         1.05393502e+00],\n",
       "       [-5.25060772e-02, -5.92373012e-01,  7.62758269e-01,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  8.76433123e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 2.24968346e+00,  1.70959465e+00,  1.67215710e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.24968346e+00, -1.05276654e+00,  1.78583195e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  7.05920842e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  3.28414053e-01,  1.10378283e+00,\n",
       "         1.44883158e+00],\n",
       "       [-2.94841818e-01, -5.92373012e-01,  6.49083415e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 2.24968346e+00, -5.92373012e-01,  1.67215710e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 5.53333275e-01, -8.22569778e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00,  3.28414053e-01,  1.27429511e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 4.32165405e-01, -5.92373012e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00, -1.31979479e-01,  1.16062026e+00,\n",
       "         5.27406285e-01],\n",
       "       [ 1.88617985e+00, -5.92373012e-01,  1.33113254e+00,\n",
       "         9.22302838e-01],\n",
       "       [ 2.49201920e+00,  1.70959465e+00,  1.50164482e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 5.53333275e-01, -5.92373012e-01,  7.62758269e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -1.05276654e+00,  1.04694540e+00,\n",
       "         2.64141916e-01],\n",
       "       [ 2.24968346e+00, -1.31979479e-01,  1.33113254e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01,  7.88807586e-01,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  9.82172869e-02,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.89829664e-01, -1.31979479e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  9.33270550e-01,\n",
       "         1.18556721e+00],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  7.62758269e-01,\n",
       "         1.44883158e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00,  3.28414053e-01,  1.21745768e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 4.32165405e-01,  7.88807586e-01,  9.33270550e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  7.62758269e-01,\n",
       "         7.90670654e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size=0.25, stratify=y, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat blueprint model\n",
    "model = Sequential()\n",
    "\n",
    "# Tentukan layer per model\n",
    "model.add(Dense(64, input_dim=4, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Tentukan loss, algoritma belajar, dan jenis evaluasi\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 81ms/step - loss: 0.9453 - accuracy: 0.6786 - val_loss: 0.9148 - val_accuracy: 0.6579\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8533 - accuracy: 0.8036 - val_loss: 0.8435 - val_accuracy: 0.7105\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7780 - accuracy: 0.8393 - val_loss: 0.7852 - val_accuracy: 0.7105\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7147 - accuracy: 0.8482 - val_loss: 0.7370 - val_accuracy: 0.7105\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6580 - accuracy: 0.8393 - val_loss: 0.6951 - val_accuracy: 0.7105\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6074 - accuracy: 0.8393 - val_loss: 0.6577 - val_accuracy: 0.7105\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5620 - accuracy: 0.8482 - val_loss: 0.6262 - val_accuracy: 0.7368\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5209 - accuracy: 0.8571 - val_loss: 0.5973 - val_accuracy: 0.7632\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4856 - accuracy: 0.8571 - val_loss: 0.5723 - val_accuracy: 0.7632\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4528 - accuracy: 0.8571 - val_loss: 0.5521 - val_accuracy: 0.7632\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4247 - accuracy: 0.8571 - val_loss: 0.5349 - val_accuracy: 0.7632\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4005 - accuracy: 0.8750 - val_loss: 0.5194 - val_accuracy: 0.7632\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.8661 - val_loss: 0.5061 - val_accuracy: 0.7895\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3593 - accuracy: 0.8750 - val_loss: 0.4960 - val_accuracy: 0.7895\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3424 - accuracy: 0.8839 - val_loss: 0.4876 - val_accuracy: 0.7895\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3271 - accuracy: 0.8839 - val_loss: 0.4795 - val_accuracy: 0.7895\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3138 - accuracy: 0.8839 - val_loss: 0.4735 - val_accuracy: 0.7895\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3003 - accuracy: 0.8750 - val_loss: 0.4666 - val_accuracy: 0.7895\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2890 - accuracy: 0.8750 - val_loss: 0.4605 - val_accuracy: 0.7895\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2778 - accuracy: 0.8839 - val_loss: 0.4527 - val_accuracy: 0.7895\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2669 - accuracy: 0.8839 - val_loss: 0.4457 - val_accuracy: 0.7895\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2572 - accuracy: 0.8929 - val_loss: 0.4386 - val_accuracy: 0.7895\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2475 - accuracy: 0.8929 - val_loss: 0.4331 - val_accuracy: 0.7895\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2382 - accuracy: 0.9018 - val_loss: 0.4274 - val_accuracy: 0.7895\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2294 - accuracy: 0.9107 - val_loss: 0.4214 - val_accuracy: 0.7895\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2208 - accuracy: 0.9107 - val_loss: 0.4167 - val_accuracy: 0.7895\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2124 - accuracy: 0.9107 - val_loss: 0.4108 - val_accuracy: 0.7895\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2045 - accuracy: 0.9196 - val_loss: 0.4053 - val_accuracy: 0.8158\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1980 - accuracy: 0.9286 - val_loss: 0.4021 - val_accuracy: 0.8421\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1900 - accuracy: 0.9286 - val_loss: 0.3917 - val_accuracy: 0.8421\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1825 - accuracy: 0.9196 - val_loss: 0.3841 - val_accuracy: 0.8684\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1759 - accuracy: 0.9375 - val_loss: 0.3803 - val_accuracy: 0.8684\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1688 - accuracy: 0.9375 - val_loss: 0.3754 - val_accuracy: 0.8684\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1634 - accuracy: 0.9375 - val_loss: 0.3703 - val_accuracy: 0.8684\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1580 - accuracy: 0.9375 - val_loss: 0.3641 - val_accuracy: 0.8684\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1520 - accuracy: 0.9375 - val_loss: 0.3604 - val_accuracy: 0.8684\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1468 - accuracy: 0.9375 - val_loss: 0.3550 - val_accuracy: 0.8684\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1421 - accuracy: 0.9464 - val_loss: 0.3495 - val_accuracy: 0.8684\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1374 - accuracy: 0.9464 - val_loss: 0.3436 - val_accuracy: 0.8684\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1329 - accuracy: 0.9554 - val_loss: 0.3375 - val_accuracy: 0.8684\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1282 - accuracy: 0.9554 - val_loss: 0.3309 - val_accuracy: 0.8684\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1240 - accuracy: 0.9554 - val_loss: 0.3251 - val_accuracy: 0.8684\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1200 - accuracy: 0.9554 - val_loss: 0.3191 - val_accuracy: 0.8684\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1160 - accuracy: 0.9554 - val_loss: 0.3129 - val_accuracy: 0.8684\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1125 - accuracy: 0.9554 - val_loss: 0.3077 - val_accuracy: 0.8684\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1096 - accuracy: 0.9554 - val_loss: 0.3014 - val_accuracy: 0.8684\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1060 - accuracy: 0.9554 - val_loss: 0.2955 - val_accuracy: 0.8684\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1026 - accuracy: 0.9554 - val_loss: 0.2906 - val_accuracy: 0.8684\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0995 - accuracy: 0.9554 - val_loss: 0.2860 - val_accuracy: 0.8684\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0970 - accuracy: 0.9554 - val_loss: 0.2820 - val_accuracy: 0.8684\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0936 - accuracy: 0.9554 - val_loss: 0.2767 - val_accuracy: 0.8684\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0908 - accuracy: 0.9554 - val_loss: 0.2702 - val_accuracy: 0.8684\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0881 - accuracy: 0.9554 - val_loss: 0.2651 - val_accuracy: 0.8684\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0853 - accuracy: 0.9643 - val_loss: 0.2608 - val_accuracy: 0.8684\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9643 - val_loss: 0.2549 - val_accuracy: 0.8684\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0806 - accuracy: 0.9643 - val_loss: 0.2501 - val_accuracy: 0.8684\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0782 - accuracy: 0.9732 - val_loss: 0.2450 - val_accuracy: 0.8684\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0760 - accuracy: 0.9821 - val_loss: 0.2396 - val_accuracy: 0.8684\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0740 - accuracy: 0.9821 - val_loss: 0.2353 - val_accuracy: 0.8684\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0717 - accuracy: 0.9821 - val_loss: 0.2318 - val_accuracy: 0.8684\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0704 - accuracy: 0.9821 - val_loss: 0.2298 - val_accuracy: 0.8684\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0685 - accuracy: 0.9911 - val_loss: 0.2254 - val_accuracy: 0.8947\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0661 - accuracy: 0.9911 - val_loss: 0.2230 - val_accuracy: 0.8947\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0647 - accuracy: 0.9911 - val_loss: 0.2214 - val_accuracy: 0.8947\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0635 - accuracy: 0.9911 - val_loss: 0.2200 - val_accuracy: 0.8947\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0624 - accuracy: 0.9911 - val_loss: 0.2150 - val_accuracy: 0.8947\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0619 - accuracy: 0.9911 - val_loss: 0.2082 - val_accuracy: 0.9211\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0585 - accuracy: 0.9911 - val_loss: 0.2054 - val_accuracy: 0.9211\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0569 - accuracy: 0.9911 - val_loss: 0.2004 - val_accuracy: 0.9211\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0555 - accuracy: 0.9911 - val_loss: 0.1961 - val_accuracy: 0.9211\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0542 - accuracy: 0.9911 - val_loss: 0.1911 - val_accuracy: 0.9211\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0532 - accuracy: 0.9911 - val_loss: 0.1871 - val_accuracy: 0.9211\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0518 - accuracy: 0.9911 - val_loss: 0.1855 - val_accuracy: 0.9211\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0509 - accuracy: 0.9911 - val_loss: 0.1829 - val_accuracy: 0.9211\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0494 - accuracy: 0.9911 - val_loss: 0.1816 - val_accuracy: 0.9211\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0486 - accuracy: 0.9911 - val_loss: 0.1811 - val_accuracy: 0.9211\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0476 - accuracy: 0.9911 - val_loss: 0.1773 - val_accuracy: 0.9211\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0465 - accuracy: 0.9911 - val_loss: 0.1759 - val_accuracy: 0.9211\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0453 - accuracy: 0.9911 - val_loss: 0.1746 - val_accuracy: 0.9211\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0450 - accuracy: 0.9911 - val_loss: 0.1744 - val_accuracy: 0.9211\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0435 - accuracy: 0.9911 - val_loss: 0.1702 - val_accuracy: 0.9211\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0428 - accuracy: 0.9911 - val_loss: 0.1678 - val_accuracy: 0.9211\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0419 - accuracy: 0.9911 - val_loss: 0.1645 - val_accuracy: 0.9211\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0415 - accuracy: 0.9821 - val_loss: 0.1625 - val_accuracy: 0.9211\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9821 - val_loss: 0.1628 - val_accuracy: 0.9211\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9911 - val_loss: 0.1621 - val_accuracy: 0.9211\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0389 - accuracy: 0.9911 - val_loss: 0.1632 - val_accuracy: 0.9211\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9911 - val_loss: 0.1618 - val_accuracy: 0.9211\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0376 - accuracy: 0.9911 - val_loss: 0.1616 - val_accuracy: 0.9211\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0372 - accuracy: 0.9911 - val_loss: 0.1587 - val_accuracy: 0.9211\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.1583 - val_accuracy: 0.9211\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9911 - val_loss: 0.1562 - val_accuracy: 0.9211\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9821 - val_loss: 0.1541 - val_accuracy: 0.9211\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9911 - val_loss: 0.1548 - val_accuracy: 0.9211\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9911 - val_loss: 0.1534 - val_accuracy: 0.9211\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9911 - val_loss: 0.1528 - val_accuracy: 0.9211\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.9911 - val_loss: 0.1485 - val_accuracy: 0.9211\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9821 - val_loss: 0.1464 - val_accuracy: 0.9211\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 0.9911 - val_loss: 0.1458 - val_accuracy: 0.9211\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9911 - val_loss: 0.1463 - val_accuracy: 0.9211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xf2d1dbc430>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isi data ke neural network dan train\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal.length          6.3\n",
       "sepal.width           3.3\n",
       "petal.length          6.0\n",
       "petal.width           2.5\n",
       "variety         Virginica\n",
       "label                   2\n",
       "Name: 100, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menggunakan data dari df\n",
    "df.iloc[100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [[6.3, 3.3, 6, 2.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.array(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3, 3.3, 6. , 2.5]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.84333333, 3.05733333, 3.758     , 1.19933333])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atribut_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82530129, 0.43441097, 1.75940407, 0.75969263])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atribut_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal.length', 'sepal.width', 'petal.length', 'petal.width', 'variety',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal.length          6.3\n",
       "sepal.width           3.3\n",
       "petal.length          6.0\n",
       "petal.width           2.5\n",
       "variety         Virginica\n",
       "label                   2\n",
       "Name: 100, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{x-mean}{std}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepalLength = (6.3 - atribut_mean[0]) / atribut_std[0]\n",
    "sepalWidth = (3.3 - atribut_mean[1]) / atribut_std[1]\n",
    "petalLength = (6 - atribut_mean[2]) / atribut_std[2]\n",
    "petalWidth = (2.5 - atribut_mean[3]) / atribut_std[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xPred = np.array([[sepalLength, sepalWidth, petalLength, petalWidth]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil = model.predict(xPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.3059023e-05, 1.1300693e-04, 9.9985397e-01]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(hasil, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
